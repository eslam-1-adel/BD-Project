{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7f159d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4d10a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.csv' with the actual file path\n",
    "file_path = 'Chicago_Crimes_2012_to_2017.csv'\n",
    "\n",
    "# Specify the delimiter used in your CSV file (e.g., ';')\n",
    "df = pd.read_csv(file_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "329fedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1d9bf0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## read the dataset\n",
    "df_pyspark=spark.read.option('header','true').csv('Chicago_Crimes_2012_to_2017.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b5c81a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=df_pyspark.drop('_c0','ID','Block','IUCR','Description','Location Description','X Coordinate','Y Coordinate','Latitude','Longitude','Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "77291491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Case Number': 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Date': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Primary Type': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Arrest': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Domestic': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Beat': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'District': 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Ward': 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Community Area': 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'FBI Code': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Year': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 842:>                                                        (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Updated On': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Assume df_pyspark is your DataFrame\n",
    "# df_pyspark = ...\n",
    "\n",
    "# Iterate over the columns and count null values\n",
    "for column in df_pyspark.columns:\n",
    "    null_count = df_pyspark.filter(col(column).isNull()).count()\n",
    "    print(f\"Number of null values in '{column}': {null_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c41a3467",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Case Number',\n",
       " 'Date',\n",
       " 'Primary Type',\n",
       " 'Arrest',\n",
       " 'Domestic',\n",
       " 'Beat',\n",
       " 'District',\n",
       " 'Ward',\n",
       " 'Community Area',\n",
       " 'FBI Code',\n",
       " 'Year',\n",
       " 'Updated On']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0914a729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Define the columns to impute\n",
    "input_cols = ['Ward', 'Community Area', 'District']\n",
    "\n",
    "# Create an Imputer object\n",
    "imputer = Imputer(\n",
    "    inputCols=input_cols,\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in input_cols]\n",
    ").setStrategy(\"mean\")\n",
    "\n",
    "# Fit and transform the DataFrame\n",
    "df_imputed = imputer.fit(df_pyspark).transform(df_pyspark)\n",
    "\n",
    "# Overwrite 'Ward', 'Community Area', and 'District' columns with imputed values\n",
    "df_imputed_overwritten = df_imputed.withColumn(\n",
    "    'Ward', \n",
    "    when(col('Ward').isNull(), col('Ward_imputed')).otherwise(col('Ward'))\n",
    ").withColumn(\n",
    "    'Community Area', \n",
    "    when(col('Community Area').isNull(), col('Community Area_imputed')).otherwise(col('Community Area'))\n",
    ").withColumn(\n",
    "    'District', \n",
    "    when(col('District').isNull(), col('District_imputed')).otherwise(col('District'))\n",
    ")\n",
    "\n",
    "# Drop the intermediate imputed columns\n",
    "df_imputed_overwritten = df_imputed_overwritten.drop('Ward_imputed', 'Community Area_imputed', 'District_imputed')\n",
    "\n",
    "# Update df_pyspark with the overwritten DataFrame\n",
    "df_pyspark = df_imputed_overwritten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1dba163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Drop rows with null values in the 'Case Number' column\n",
    "df_pyspark = df_pyspark.na.drop(subset=['Case Number'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2df1265f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Case Number': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Date': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Primary Type': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Arrest': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Domestic': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Beat': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'District': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Ward': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Community Area': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'FBI Code': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Year': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 883:>                                                        (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in 'Updated On': 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Assume df_pyspark is your DataFrame\n",
    "# df_pyspark = ...\n",
    "\n",
    "# Iterate over the columns and count null values\n",
    "for column in df_pyspark.columns:\n",
    "    null_count = df_pyspark.filter(col(column).isNull()).count()\n",
    "    print(f\"Number of null values in '{column}': {null_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d60bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00348c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4d5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7680231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f322f86e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
